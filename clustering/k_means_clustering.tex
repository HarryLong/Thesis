\section{K-Means Clustering} \label{sec:clustering}

K-means is a well known and broadly used vector-quantization clustering algorithm \cite{Jain2010} which groups points into clusters based on the euclidean distance from a set of \textit{K} cluster means. It has been used to to tackle a wide range of problems including character recognition \cite{Perrone2000}, image segmentation \cite{Bradley1998,Kanungo2002} and compression \cite{Kanungo2002}.\\
The algorithm is of complexity O(N) and can be optimized to make use of parallel architectures \cite{Xu2005}. Efficiency is a key requirement for the terrain clustering process in order to provide interactive user feedback, irrespective of terrain size.\\
K-means often fails to produce adequate clusters when dealing with large dimensionality data sets \cite{Sun2012}. Because the data here has only four dimensions (slope, temperature, illumination and soil humidity), it is well-fitted. \\
Common downsides of K-means clustering, however, is the necessity to configure the number of clusters to produce \textit{K} and the selection of the initial \textit{K} points to act as the cluster seeds. How these are handled are discussed in sections \ref{subsec:n_cluster_conf} and \ref{subsec:init_clusters} respectively.\\

Given a set of data points \textit{P} and a configured value \textit{k}, k-means clustering behaves as follows:
\begin{enumerate}
\item Choose \textit{K} points at random to act as the seed cluster means, \textit{C$_{mean}$}.
\item Iterate through every data point \textit{P$_{n}$} from \textit{P} and calculate its Euclidean distance from each cluster mean using equation \ref{eq:cluster_dist_calc}. Point \textit{P} becomes a member of its closest cluster. 
\item Use the members of each cluster to calculate the new cluster means. 
\item Repeat from step 2. 
\end{enumerate}

\begin{equation} \label{eq:cluster_dist_calc}
D(A,B) = \sum_{n=1}^{m} (A_{n} - B_{n}) ^{2}
\end{equation}

Where: \textbf{A} and \textbf{B} are either data points or a cluster mean; \textbf{n} $\in$ \textbf{$\mathbb{R}_{m}$} is the dimensionality of the data set; \textbf{A$_{n}$} is the value of data point A in dimension \textit{n}.

\subsection{Normalisation}

The Euclidean distance calculation outlined in equation \ref{eq:cluster_dist_calc} works well when all values have similar scale. Unfortunately, this is not the case for terrain resource data as illumination, slope, temperature and soil humidity are all measured in different units. This means that a one millimetre change in soil humidity will have as much of an influence on clustering as a one degree change in temperature. To equalise the effect on clustering across all resources, normalisation is performed based on the range of the individual resources. Equation \ref{eq:cluster_dist_calc_real} is used to calculate the Euclidean distance between two terrain positions (or cluster means) \textit{A} and \textit{B} for clustering.

\begin{equation} \label{eq:cluster_dist_calc_real}
D(A,B) = 
(\frac{\textit{S}(A) - \textit{S}(B)}{R_{S}})^{2} + 
\sum_{n=1}^{12}(
(\frac{\textit{T}_{n}(A) - \textit{T}_{n}(B)}{R_{T}}) ^{2} + 
(\frac{\textit{H}_{n}(A) - \textit{H}_{n}(B)}{R_{H}}) ^{2} + 
(\frac{\textit{I}_{n}(A) - \textit{I}_{n}(B)}{R_{I}}) ^{2} )
\end{equation}

Where:\textit{S(x)} is the slope of a point or cluster mean x; \textit{R$_{T}$(x)} is the slope range; ;\textit{T$_{n}$(x)} is the temperature of point or cluster mean x at month n; \textit{R$_{T}$(x)} is the temperature range; \textit{H$_{n}$(x)} is the soil humidity of point or cluster mean x at month n; \textit{R$_{H}$(x)} is the humidity range; \textit{I$_{n}$(x)} is the illumination of point or cluster mean x at month n; \textit{R$_{I}$(x)} is the illumination range; 

\subsection{Configuring the Number of Clusters, K} \label{subsec:n_cluster_conf}

The value of \textit{K} will affect the number of ecosystem simulators which need to be run when placing vegetation on the terrain. Although larger values will potentially result in more realistic vegetation distributions, the added simulations will require additional processing time. Choosing a good value for \textit{K} is therefore about finding a balance between realism and processing time and, as such, depends on user requirements. Because of this, the value of \textit{K} is required as input from the user before the clustering is performed.

\subsection{Choosing Seed Cluster Means} \label{subsec:init_clusters}

A downside of classic K-means clustering techniques is that clusters are non-reproducible. This is because the final clusters depend heavily on the initial seed points which were chosen to act as the cluster means. As these are selected at random, different runs will result in different clusters. Reproducibility is important here, however, as if the clusters cannot be reproduced neither will the final terrain. To ensure reproducibility, the terrain positions to act as the initial clusters are chosen using a pseudo-random number generator with a predefined and fixed seed.
